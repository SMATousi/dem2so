{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcd56b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import wandb\n",
    "from os.path import splitext\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import logging\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as TF\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import imageio.v2 as imageio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "from model import *\n",
    "from utils import *\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0e41487",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fca3879",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstmmc\u001b[0m (\u001b[33mtousi-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macula/SMATousi/Gullies/ground_truth/google_api/training_process/DEM2SO/code/dem2so/wandb/run-20240220_153656-2vzoxazn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tousi-team/DEM2SO/runs/2vzoxazn' target=\"_blank\">lunar-festival-14</a></strong> to <a href='https://wandb.ai/tousi-team/DEM2SO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tousi-team/DEM2SO' target=\"_blank\">https://wandb.ai/tousi-team/DEM2SO</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tousi-team/DEM2SO/runs/2vzoxazn' target=\"_blank\">https://wandb.ai/tousi-team/DEM2SO/runs/2vzoxazn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c82b6401",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_dir = '/home/macula/SMATousi/Gullies/ground_truth/google_api/training_process/DEM2SO/New_Data/dem'\n",
    "so_dir = '/home/macula/SMATousi/Gullies/ground_truth/google_api/training_process/DEM2SO/New_Data/so'\n",
    "rgb_dir = '/home/macula/SMATousi/Gullies/ground_truth/google_api/training_process/DEM2SO/New_Data/rgb'\n",
    "pretrained_model_path = '/home/macula/SMATousi/cluster/docker-images/dem2so_more_data/pre_models/B3_rn50_moco_0099_ckpt.pth'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9acd4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = RGB_RasterTransform()\n",
    "    \n",
    "dataset = RGB_RasterTilesDataset(dem_dir=dem_dir, so_dir=so_dir, rgb_dir=rgb_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35d0c840",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "learning_rate = 0.0001\n",
    "epochs = 1\n",
    "number_of_workers = 0\n",
    "image_size = 128\n",
    "val_percent = 0.1\n",
    "\n",
    "n_val = int(len(dataset) * val_percent)\n",
    "n_train = len(dataset) - n_val\n",
    "train, val = random_split(dataset, [n_train, n_val])\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=number_of_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=number_of_workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "990e1f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = RGB_DEM_to_SO(resnet_output_size=(8, 8), \n",
    "                            fusion_output_size=(128, 128), \n",
    "                            model_choice = \"Unet_1\", \n",
    "                            resnet_saved_model_path=pretrained_model_path,\n",
    "                            dropout_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5e92a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bc9451d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model_epoch_200:v6, 144.43MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:8.6\n"
     ]
    }
   ],
   "source": [
    "artifact = run.use_artifact('tousi-team/RGB_DEM_2_SO/model_epoch_200:v6', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7308490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./artifacts/model_epoch_200:v6/model_epoch_200.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "83e8220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mIOU(label, pred, num_classes=9):\n",
    "    pred = F.softmax(pred, dim=1)              \n",
    "    pred = torch.argmax(pred, dim=1).squeeze(1)\n",
    "    iou_list = list()\n",
    "    present_iou_list = list()\n",
    "\n",
    "    pred = pred.view(-1)\n",
    "    label = label.view(-1)\n",
    "    # Note: Following for loop goes from 0 to (num_classes-1)\n",
    "    # and ignore_index is num_classes, thus ignore_index is\n",
    "    # not considered in computation of IoU.\n",
    "    for sem_class in range(num_classes):\n",
    "        pred_inds = (pred == sem_class)\n",
    "        target_inds = (label == sem_class)\n",
    "        if target_inds.long().sum().item() == 0:\n",
    "            iou_now = float('nan')\n",
    "        else: \n",
    "            intersection_now = (pred_inds[target_inds]).long().sum().item()\n",
    "            union_now = pred_inds.long().sum().item() + target_inds.long().sum().item() - intersection_now\n",
    "            iou_now = float(intersection_now) / float(union_now)\n",
    "            present_iou_list.append(iou_now)\n",
    "            # print(iou_now)\n",
    "        iou_list.append(iou_now)\n",
    "    return present_iou_list, np.mean(present_iou_list)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def mIOU_with_tolerance(label, pred, num_classes=9):\n",
    "    pred = torch.softmax(pred, dim=1)\n",
    "    pred = torch.argmax(pred, dim=1)\n",
    "\n",
    "    # Flatten label and prediction tensors\n",
    "    pred = pred.view(-1)\n",
    "    label = label.view(-1)\n",
    "\n",
    "    iou_list = []\n",
    "    present_iou_list = []\n",
    "\n",
    "    for sem_class in range(num_classes):\n",
    "        # Adjusting for tolerance: consider predictions that are one level above or below the target class\n",
    "        pred_inds = ((pred == sem_class) | (pred == sem_class - 1) & (pred > 0) | (pred == sem_class + 1) & (pred < num_classes - 1))\n",
    "        target_inds = ((label == sem_class) | (label == sem_class - 1) & (label > 0) | (label == sem_class + 1) & (label < num_classes - 1))\n",
    "\n",
    "        if target_inds.long().sum().item() == 0:\n",
    "            iou_now = float('nan')  # Class not present in the label\n",
    "        else:\n",
    "            intersection_now = (pred_inds & target_inds).long().sum().item()\n",
    "            union_now = pred_inds.long().sum().item() + target_inds.long().sum().item() - intersection_now\n",
    "            iou_now = float(intersection_now) / float(union_now)\n",
    "            present_iou_list.append(iou_now)\n",
    "\n",
    "        iou_list.append(iou_now)\n",
    "\n",
    "    # Compute the mean of the present IoU scores, ignoring NaNs\n",
    "    valid_iou_scores = [iou for iou in present_iou_list if not np.isnan(iou)]\n",
    "    return present_iou_list, valid_iou_scores, np.mean(valid_iou_scores) if valid_iou_scores else float('nan')\n",
    "\n",
    "# Note: You'll need to replace 'F.softmax' and 'torch.argmax' with the appropriate calls to your prediction tensor,\n",
    "# and ensure your label and pred tensors are in the correct shape and format.\n",
    "\n",
    "def normalize_and_discretize_for_mIoU(label, pred, num_classes=9):\n",
    "    # Ensure pred and label are torch tensors\n",
    "    pred = torch.tensor(pred, dtype=torch.float32)\n",
    "    label = torch.tensor(label, dtype=torch.float32)\n",
    "    \n",
    "    # Normalize by dividing by the maximum value in each tensor\n",
    "    pred_argmax = torch.argmax(pred, dim=1)\n",
    "    pred_max = pred_argmax.max() if pred_argmax.max() > 0 else 1  # Avoid division by zero\n",
    "    label_max = label.max() if label.max() > 0 else 1\n",
    "    pred_normalized = pred_argmax / pred_max\n",
    "    label_normalized = label / label_max\n",
    "    \n",
    "    print(pred_normalized.shape)\n",
    "    \n",
    "    print(label_normalized.shape)\n",
    "\n",
    "    # Discretize the normalized values\n",
    "    pred_discrete = torch.round(pred_normalized * (num_classes - 1)).long()\n",
    "    label_discrete = torch.round(label_normalized * (num_classes - 1)).long()\n",
    "\n",
    "    # Flatten the tensors if they're not already, to prepare for mIoU calculation\n",
    "    pred_flat = pred_discrete.view(-1)\n",
    "    label_flat = label_discrete.view(-1)\n",
    "\n",
    "    iou_list = []\n",
    "    present_iou_list = []\n",
    "\n",
    "    for sem_class in range(num_classes):\n",
    "        pred_inds = (pred_flat == sem_class)\n",
    "        target_inds = (label_flat == sem_class)\n",
    "\n",
    "        if target_inds.long().sum().item() == 0:\n",
    "            iou_now = float('nan')  # Class not present in the label\n",
    "        else:\n",
    "            intersection_now = (pred_inds & target_inds).long().sum().item()\n",
    "            union_now = pred_inds.long().sum().item() + target_inds.long().sum().item() - intersection_now\n",
    "            iou_now = float(intersection_now) / float(union_now)\n",
    "            present_iou_list.append(iou_now)\n",
    "\n",
    "        iou_list.append(iou_now)\n",
    "\n",
    "    # Compute the mean of the present IoU scores, ignoring NaNs\n",
    "    valid_iou_scores = [iou for iou in present_iou_list if not np.isnan(iou)]\n",
    "    return present_iou_list, np.mean(valid_iou_scores) if valid_iou_scores else float('nan')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "def5f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "val_iter = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "216e814b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 128])\n",
      "torch.Size([1, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/ipykernel_launcher.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/ipykernel_launcher.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "batch = next(val_iter)\n",
    "dem = batch['DEM']\n",
    "so = batch['SO']\n",
    "rgbs = batch['RGB']\n",
    "\n",
    "start = time.time()\n",
    "val_outputs = model(dem, rgbs)\n",
    "end = time.time()\n",
    "\n",
    "loss = criterion(val_outputs, so)\n",
    "\n",
    "present_iou_list, iou = mIOU(so, val_outputs)\n",
    "present_iou_list_tol, valid_iou_scores, iou_tol = mIOU_with_tolerance(so, val_outputs)\n",
    "present_iou_list_norm, iou_norm = normalize_and_discretize_for_mIoU(so, val_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "29c5b07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.851401179941003,\n",
       " 0.8007926331740296,\n",
       " 0.4883808095952024,\n",
       " 0.3969270166453265,\n",
       " 0.18813314037626627,\n",
       " 0.0,\n",
       " 0.028985507246376812,\n",
       " 0.0]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "present_iou_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a80fbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9043030031376065,\n",
       " 0.8539379474940334,\n",
       " 0.8753364007292299,\n",
       " 0.6728232189973615,\n",
       " 0.5581283164495899,\n",
       " 0.21895424836601307,\n",
       " 0.04482758620689655,\n",
       " 0.02702702702702703,\n",
       " 0.0]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "present_iou_list_tol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "809fcdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.851401179941003,\n",
       " 0.8007926331740296,\n",
       " 0.0,\n",
       " 0.08716439867598381,\n",
       " 0.18813314037626627,\n",
       " 0.0,\n",
       " 0.11494252873563218,\n",
       " 0.0]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "present_iou_list_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113aa9da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
